
// The vertex shader calculates the camera distance to the mesh, which determines:
//
//   - How many layers of fur are visible
//   - How far apart the layers are
//   - How much detail is visible (ie. "FURFADEIN")
// 
// The vertex shader is also responsible for determining where the skin layer is.
// At far distances only the skin layer will be visible, but as the camera moves closer
// the skin layer will shrink and be replaced with layers of fur generated by the geometry shader.
//
// The vertex shader also pre-calculates as much lighting as possible. This isn't as
// accurate as doing it all in the fragment shader, but it's faster.

#include "FastFur-Function-Wind.cginc"


#if defined(FUR_SKIN_LAYER)
fragInput vert(meshData v)
{
	fragInput o = (fragInput)0;
#else
hullGeomInput vert(meshData v)
{
	hullGeomInput o = (hullGeomInput)0;
#endif


	//--------------------------------------------------------------------------------
	// Show/Hide in Mirror
	if (_MirrorShowHide > 0.5)
	{
		if ((_MirrorShowHide == 1 && _VRChatMirrorMode > 0.5) || (_MirrorShowHide == 2 && _VRChatMirrorMode < 0.5))
		{
#if defined(FUR_SKIN_LAYER)
			o.pos = float4(0, 0, 1e9, 1);
#else
			o.VISIBLELAYERS = -1;
#endif
			return o;
		}
	}



	//--------------------------------------------------------------------------------
	// UV Discard
	float2 uv = _SelectedUV == 3 ? v.uv3 : _SelectedUV == 2 ? v.uv2 : _SelectedUV == 1 ? v.uv1 : v.uv0;
	if (_EnableUDIMDiscardOptions > 0)
	{
		float2 discardUV = _UDIMDiscardUV == 3 ? v.uv3 : _UDIMDiscardUV == 2 ? v.uv2 : _UDIMDiscardUV == 1 ? v.uv1 : v.uv0;
		float2 uvGroup = floor(discardUV);
		if (all(uvGroup >= 0 && uvGroup < 4))
		{
			float uvGrid[16] = {
				_UDIMDiscardRow0_0, _UDIMDiscardRow0_1, _UDIMDiscardRow0_2, _UDIMDiscardRow0_3,
				_UDIMDiscardRow1_0, _UDIMDiscardRow1_1, _UDIMDiscardRow1_2, _UDIMDiscardRow1_3,
				_UDIMDiscardRow2_0, _UDIMDiscardRow2_1, _UDIMDiscardRow2_2, _UDIMDiscardRow2_3,
				_UDIMDiscardRow3_0, _UDIMDiscardRow3_1, _UDIMDiscardRow3_2, _UDIMDiscardRow3_3
			};

			if (uvGrid[uvGroup.x + uvGroup.y * 4] > 0)
			{
#if defined(FUR_SKIN_LAYER)
				o.pos = float4(0, 0, 1e9, 1);
#else
				o.VISIBLELAYERS = -1;
#endif
				return o;
			}
		}
	}



	//--------------------------------------------------------------------------------
	// Determine render quality. There are 9 options:
	//    _V4QualityEditor
	//    _V4QualityVR
	//    _V4Quality2D
	//    _V4QualityVRMirror
	//    _V4Quality2DMirror
	//    _V4QualityCameraView
	//    _V4QualityStreamCamera
	//    _V4QualityCameraPhoto
	//    _V4QualityScreenshot
	//
	// _VRChatCameraMode
	//    0 - Rendering normally
	//    1 - Rendering in VR handheld camera
	//    2 - Rendering in Desktop handheld camera
	//    3 - Rendering for a screenshot
	//
	// _VRChatMirrorMode
	//    0 - Rendering normally, not in a mirror
	//    1 - Rendering in a mirror viewed in VR
	//    2 - Rendering in a mirror viewed in desktop mode

	// If we are rendering in stereo, then the quality is always _V4QualityVR. Mirrors, cameras, etc..., aren't actually rendered in stereo, even if we are in VR while looking at them.
	// Since this is handled by a shader keyword, this means VR will be slightly faster than the other options
#if defined (USING_STEREO_MATRICES)
	float quality = _V4QualityVR;
#else
	float quality = _VRChatCameraMode < -0.5 ? _V4QualityEditor : _V4Quality2D;
	if (_VRChatCameraMode > 2.5)
	{
		quality = _V4QualityScreenshot;
	}
	else if (_VRChatCameraMode > 0.5)
	{
		quality = (_ScreenParams.y == 720) ? _V4QualityCameraView : (_ScreenParams.y == 1080 || _ScreenParams.y == 1440 || _ScreenParams.y == 2160 || _ScreenParams.y == 4320) ? _V4QualityCameraPhoto : _V4QualityStreamCamera;
	}
	else if (_VRChatMirrorMode > 0.5)
	{
		quality = _VRChatMirrorMode > 1.5 ? _V4Quality2DMirror : _V4QualityVRMirror;
	}
#endif
	// Bump "Fastest" up to 100, and "Very Fast" up to 125
	quality += saturate(2 - quality) * 0.5;
	quality = max(0, min(15.5, quality + _OverrideQualityBias * 0.02));

	// unity_DeltaTime.w gives us 'smoothed-out' FPS (that isn't actually all that smooth, but it's what we get)
// REMOVED in RC.1 //	if (_MinimumFPSTarget > 0 && unity_DeltaTime.x > 1.0)
// REMOVED in RC.1 //	{
// REMOVED in RC.1 //		float speedAdjustment = max(0.35, saturate(unity_DeltaTime.w / _MinimumFPSTarget));
// REMOVED in RC.1 //		quality *= speedAdjustment;
// REMOVED in RC.1 //	}

	float shellDensity = BASE_SHELL_COUNT * LAYER_DENSITY * (1 + quality);


	//--------------------------------------------------------------------------------
	// Before we do anything else, how far away are we? If we are beyond the maximum distance,
	// then we want to abort RIGHT AWAY. The faster we can abort, the higher the average FPS.
	float3 worldPos = mul(unity_ObjectToWorld, v.vertex);

	// We need both eyes to match. We don't want the layers shifting between eyes (due to a
	// difference in the number of layers to render), because that will mess up depth perception.
#if defined (USING_STEREO_MATRICES)
	float3 viewVector = (unity_StereoWorldSpaceCameraPos[0].xyz + unity_StereoWorldSpaceCameraPos[1].xyz) * 0.5 - worldPos;
#else
	float3 viewVector = _WorldSpaceCameraPos.xyz - worldPos;
#endif
	float viewDistance = length(viewVector);
#if !defined(FUR_SKIN_LAYER)
	o.VIEWDISTANCE = viewDistance;
#endif
	viewDistance = max(0.01, viewDistance + _OverrideDistanceBias);


	//--------------------------------------------------------------------------------
	// Calculate the maximum apparent size of the fur.

	float worldScale = length(mul((float3x3) unity_ObjectToWorld, v.normal)) * _ScaleCalibration * _OverrideScale;
	float worldThickness = worldScale * 0.95 * _FurShellSpacing;
	float clampedWorldThickness = max((min(worldThickness, 0.025) + 0.025) * 0.5, quality > 14.9 ? worldThickness : (min(worldThickness, 0.05) + min(worldThickness, 0.035)) * 0.5);
#if !defined (FUR_SKIN_LAYER)
	// Should we abort early? This culling is very aggressive, and all triangles that belong
	// to this vertex will be culled, even if the other verticies are within range.
	float cutoffDistance = max(1.0, min(10.0, clampedWorldThickness * shellDensity)) + 0.25;
	if (viewDistance > cutoffDistance)
	{
		o.VISIBLELAYERS = -1;
		return o;
	}
#endif



	//--------------------------------------------------------------------------------
	// Stereo Rendering support
	//
	// This is a good place to put my notes about how this works. The Unity engine offers 4 different options:
	// 
	// "MultiPass" (is there a way to detect this?)
	// "SinglePass" UNITY_SINGLE_PASS_STEREO - This is what VR Chat currently uses.
	// "SinglePassInstanced" UNITY_STEREO_INSTANCING_ENABLED - This is VR Chat is going to switch to.
	// "SinglePassMultiview" UNITY_STEREO_MULTIVIEW_ENABLED (I think?)
	// 
	// The XR plugin can render "MultiPass" or "SinglePassInstanced", so we can test those in the editor,
	// but "SinglePass" needs to be tested in-game.
	// 
	// All modes except "SinglePassInstanced" will 'just work' if we use Unity's standard macros/functions.
	// However, we need to be aware of how they work if we want to calculate an average between both eyes. 
	// 
	// 'unity_StereoEyeIndex' will indicate which eye is being rendered, and it will be used by Unity's macros
	// automatically. To calculate an average for distance, relative position, etc..., we could just look at the
	// underlying arrays and average them. However, things that require a screen-space average need to be aware that
	// 'UNITY_SINGLE_PASS_STEREO' only renders to half the screen-space per eye, while the other modes set the
	// screen-space as half the texture, which means they fill the entire screen-space. The easiest way to handle all
	// these possibilities it to manually set 'unity_StereoEyeIndex' for each eye before running the macros, then put
	// 'unity_StereoEyeIndex' back to its original value when we are done.
	// 
	// "SinglePassInstanced" has additional requirements. Since the CPU isn't creating the two instances, it can't set
	// different variables for each. So we need to pass-along the GPU instance number, which then gets
	// used to set 'unity_StereoEyeIndex', which is what the macros/functions rely on to work.
	// 
	// First, there are 2 different macros that need to be included in the data structures.
	// The first one is UNITY_VERTEX_INPUT_INSTANCE_ID, which needs to go into the input data for the vertex shader.
	// Unity will change what these macros do as-needed, but typically when SPSI is active they do the following:
	// 
	// UNITY_VERTEX_INPUT_INSTANCE_ID                  ->   uint instanceID : SV_InstanceID;
	//
	// Second, the input data of every stage after the vertex shader needs to contain UNITY_VERTEX_OUTPUT_STEREO:
	// 
	// UNITY_VERTEX_OUTPUT_STEREO                      ->   uint stereoTargetEyeIndex : SV_RenderTargetArrayIndex;
	//
	//
	// Now comes the processing. At the start of the vertex shader we need to use UNITY_SETUP_INSTANCE_ID(v), which
	// extracts the information it needs from the input data (exactly how I'm not showing here, because there are a
	// lot of variations) and stores it in variables for use later:
	//
	// UNITY_SETUP_INSTANCE_ID(v)                      ->   unity_StereoEyeIndex = inputInstanceID & 0x01;
	//                                                      unity_InstanceID = unity_BaseInstanceID + (inputInstanceID >> 1);
	//
	//
	// This macro makes sure everything is initialized with 0:
	// 
	// UNITY_INITIALIZE_OUTPUT(type,name)              ->   name = (type)0;
	//
	//
	// We then need to put the data into the output data structure:
	//
	// UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(output)   ->   output.stereoTargetEyeIndex = unity_StereoEyeIndex;
	//
	//
	// So that takes care of the vertex shader, but what about the hull, domain, and geometry shaders? In my case,
	// the hull and domain shaders are copying whole data structures, so the stereoTargetEyeIndex data is getting
	// copied to the next stage automatically. I don't need to use any special macros for them.
	// 
	// The geomtery shader has to convert from hullGeomInput to fragInput, so it does need to use a macro to ensure
	// the data gets copied:
	// 
	// UNITY_TRANSFER_VERTEX_OUTPUT_STEREO(input, output) ->   output.stereoTargetEyeIndex = input.stereoTargetEyeIndex;
	//
	// Finally, both the geometry and fragment shaders may need to know the unity_StereoEyeIndex, because some of the macros
	// they use may need it. So we add this macro at the start of both of them:
	// 
	// UNITY_SETUP_STEREO_EYE_INDEX_POST_VERTEX(input)    ->   unity_StereoEyeIndex = input.stereoTargetEyeIndex;
	// 
	UNITY_SETUP_INSTANCE_ID(v);
#if defined(FUR_SKIN_LAYER)
	UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(o);
#else
	UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(o);
#endif



	//--------------------------------------------------------------------------------
	// Convert normals to world space
	o.worldPos.xyz = worldPos;
	o.worldNormal.xyz = UnityObjectToWorldNormal(v.normal);// Normalized
	o.uv.xy = uv;
	float3 viewDir = normalize(viewVector);



	//--------------------------------------------------------------------------------
	// Get height samples. We don't want any filtering.
	int4 uvInt = int4(floor(frac(uv) * _FurShapeMap_TexelSize.zw), 0, 0);
	float4 furShape = _FurShapeMap.Load(uvInt);
	//float4 furShape = _FurShapeMap.SampleLevel(my_point_repeat_sampler, uv, 0);

#if defined(FUR_SKIN_ONLY)
	furShape.z = 0;
#else
	//--------------------------------------------------------------------------------
	// Apply optional height masks
	if (_FurShapeMask1Bits > 0)
	{
		int4 uvIntMask = int4(floor(frac(uv) * _FurShapeMask1_TexelSize.zw), 0, 0);
		float4 furMask = _FurShapeMask1.Load(uvIntMask);
		//float4 furMask1 = _FurShapeMask1.SampleLevel(my_point_repeat_sampler, uv, 0);
		if (_FurShapeMask1Bits & 1) furShape.z = min(furShape.z, furMask.x);
		if (_FurShapeMask1Bits & 2) furShape.z = min(furShape.z, furMask.y);
		if (_FurShapeMask1Bits & 4) furShape.z = min(furShape.z, furMask.z);
		if (_FurShapeMask1Bits & 8) furShape.z = min(furShape.z, furMask.w);
	}
	if (_FurShapeMask2Bits > 0)
	{
		int4 uvIntMask = int4(floor(frac(uv) * _FurShapeMask2_TexelSize.zw), 0, 0);
		float4 furMask = _FurShapeMask2.Load(uvIntMask);
		//float4 furMask = _FurShapeMask2.SampleLevel(my_point_repeat_sampler, uv, 0);
		if (_FurShapeMask2Bits & 1) furShape.z = min(furShape.z, furMask.x);
		if (_FurShapeMask2Bits & 2) furShape.z = min(furShape.z, furMask.y);
		if (_FurShapeMask2Bits & 4) furShape.z = min(furShape.z, furMask.z);
		if (_FurShapeMask2Bits & 8) furShape.z = min(furShape.z, furMask.w);
	}
	if (_FurShapeMask3Bits > 0)
	{
		int4 uvIntMask = int4(floor(frac(uv) * _FurShapeMask3_TexelSize.zw), 0, 0);
		float4 furMask = _FurShapeMask3.Load(uvIntMask);
		//float4 furMask = _FurShapeMask3.SampleLevel(my_point_repeat_sampler, uv, 0);
		if (_FurShapeMask3Bits & 1) furShape.z = min(furShape.z, furMask.x);
		if (_FurShapeMask3Bits & 2) furShape.z = min(furShape.z, furMask.y);
		if (_FurShapeMask3Bits & 4) furShape.z = min(furShape.z, furMask.z);
		if (_FurShapeMask3Bits & 8) furShape.z = min(furShape.z, furMask.w);
	}
	if (_FurShapeMask4Bits > 0)
	{
		int4 uvIntMask = int4(floor(frac(uv) * _FurShapeMask4_TexelSize.zw), 0, 0);
		float4 furMask = _FurShapeMask4.Load(uvIntMask);
		//float4 furMask = _FurShapeMask4.SampleLevel(my_point_repeat_sampler, uv, 0);
		if (_FurShapeMask4Bits & 1) furShape.z = min(furShape.z, furMask.x);
		if (_FurShapeMask4Bits & 2) furShape.z = min(furShape.z, furMask.y);
		if (_FurShapeMask4Bits & 4) furShape.z = min(furShape.z, furMask.z);
		if (_FurShapeMask4Bits & 8) furShape.z = min(furShape.z, furMask.w);
	}
#endif

	float thicknessSample = furShape.z < _FurMinHeight ? 0.0 : furShape.z;
	float maxThickness = worldThickness * thicknessSample;



	//--------------------------------------------------------------------------------
	// Calculate the apparent size of the fur. Use that to determine how many shells
	// need to be rendered, and the amount of details to fade-in.
	float clampedThickness = max((min(maxThickness, 0.025) + 0.025) * 0.5, quality > 14.9 ? maxThickness : (min(maxThickness, 0.05) + min(maxThickness, 0.035)) * 0.5);
	float furApparentSize = clampedThickness / viewDistance;
	float shellsToRender = furApparentSize * shellDensity;

	// Are we past the maximum distance? This culling check isn't as aggressive as the
	// early culling. If the vertex fails this check it will still get rendered if any
	// of the other 2 vertices of the triangle are within range.
	float maxDistance = max(1, min(10, clampedThickness * shellDensity));
	shellsToRender *= viewDistance > maxDistance ? 0 : 1;

	o.FURFADEIN = max(0.025, saturate(invLerp(maxDistance, 0.3, viewDistance)));



	//--------------------------------------------------------------------------------
	// Calculate skin position
	float skinZ = 0;
#if defined(FUR_SKIN_LAYER)
	if (_BodyExpansion > 0 || _BodyShrinkOffset > 0) {
#endif
		float resizeFactor = saturate(thicknessSample - _BodyResizeCutoff) / (1 - _BodyResizeCutoff);

		// Calculate a negative offset in world space to the skin position based on the fur height
		float3 bodyShrink = o.worldNormal.xyz * _BodyShrinkOffset * maxThickness * -0.40;
		o.worldPos.xyz += bodyShrink;

		// Calculate where the skin should be (0-1) relative to the thickness of the fur
		float skinFactor = saturate(1 - (o.FURFADEIN * o.FURFADEIN)) * SKIN_CUTOFF * _BodyExpansion;
		skinZ = skinFactor * resizeFactor;
#if defined(FUR_SKIN_LAYER)
	}
#endif



#if !defined (PREPASS)
	//--------------------------------------------------------------------------------
	// If we need the normal map in the fragment shader, then we will also need the tangent
	float4 worldTangent = float4(UnityObjectToWorldDir(v.tangent.xyz), v.tangent.w);
	worldTangent.xyz = normalize(worldTangent.xyz);
	float3 worldBinormal = normalize(cross(o.worldNormal.xyz, worldTangent.xyz) * (worldTangent.w * unity_WorldTransformParams.w));

#if defined(FUR_SKIN_LAYER) && defined(_NORMALMAP)
	if (_PBSSkin > 0.0 && _PBSSkinStrength > 0.0)
	{
		o.worldTangent = worldTangent;
	}
#endif
#endif



	//--------------------------------------------------------------------------------
	// Calculate effects from wind, movement, and touch
	float3 windVector = (float3)0;
	float3 windTurbulence = (float3)0;
	float3 touchVector = (float3)0;

	if (_EnableWind > 0 && _WindSpeed > 0) windVector = calculateWind(o.worldPos.xyz, uv.xy, windTurbulence);

	// Apply the effects of movement as additional wind
	if (_MovementStrength > 0)
	{
		windVector += mul(unity_ObjectToWorld, float4(float3(_VelocityX, _VelocityY, _VelocityZ) * _MovementStrength, 0)) * 0.25;
	}

	// AudioLink hair movement
	if (_AudioLinkEnable > 0 && _AudioLinkHairVibration > 0 && _AudioTexture_TexelSize.z > 16)
	{
		float4 audioIntensityFilter0 = _AudioTexture[uint2(8, 22)];
		float4 audioIntensityFilter1 = _AudioTexture[uint2(27, 28)];
		float4 audioIntensityFilter2 = _AudioTexture[uint2(26, 28)];
		float4 audioIntensityFilter3 = _AudioTexture[uint2(25, 28)];
		float4 audioIntensityFilter4 = _AudioTexture[uint2(24, 28)];

		windVector.y += ((audioIntensityFilter0.r + audioIntensityFilter0.b) - (audioIntensityFilter4.r + audioIntensityFilter4.b)) * _AudioLinkHairVibration;
		windVector.x += (audioIntensityFilter1.r - audioIntensityFilter3.b) * _AudioLinkHairVibration;
		windVector.z += (audioIntensityFilter2.b - audioIntensityFilter4.r) * _AudioLinkHairVibration;
	}



#if !defined(FUR_SKIN_LAYER)
	// The FURCULLTEST is used by the hull shader to throw out backwards geometry. We also use it to identify edge geometry so that
	// we can enhance it. We want this to match in both eyes, so that both eyes see the exact same number of layers.
	// -1 = Directly facing the camera, 1 = Directly facing away from the camera
#if defined (USING_STEREO_MATRICES)
	o.FURCULLTEST = dot(o.worldNormal.xyz, normalize(o.worldPos.xyz - ((unity_StereoWorldSpaceCameraPos[0] + unity_StereoWorldSpaceCameraPos[1]) * 0.5)));
#else
	o.FURCULLTEST = dot(o.worldNormal.xyz, normalize(o.worldPos.xyz - _WorldSpaceCameraPos));
#endif


	//--------------------------------------------------------------------------------
	// Touch detection
#define FUR_CONTACT_CULLTEST -0.15
	if (_FurTouchStrength > 0 && maxThickness > 0.0025 && o.FURCULLTEST < FUR_CONTACT_CULLTEST && viewDistance < 1.0)
	{
		// Do we have a valid _CameraDepthTexture? The blue channel should be 0. If it isn't, then that means
		// we are actually looking at the Unity default blank grey texture, so blue will be 0.2176376, because
		// that's 0.5 ^ 2.2 (Note: _CameraDepthTexture_TexelSize.z > 16 doesn't work for some reason)
		if(SAMPLE_RAW_DEPTH_TEXTURE_LOD(_CameraDepthTexture, float4(0.5, 0.5, 4, 0)).b < 0.01)
		{
			float contactActive = 2.0;

			if (_OcclusionMap_TexelSize.z > 16)
			{
				int4 uvInt = int4(floor(frac(uv) * _OcclusionMap_TexelSize.zw), 0, 0);
				contactActive = _FurTouchThreshold + _OcclusionMap.Load(uvInt).r;
			}

			// NOTE: This only works if the shadows have been set to minimum, so we force that in the shadow caster if
			// contact detecting is active.
			if (contactActive >= 1.0)
			{
				// What's the minimum cutoff? The lower this is, the more false triggers.
				float insideCutoff = maxThickness * 0.1;
				// Since we can only 'see' the back of a hand/finger, how thick do we assume the hand/finger to be?
				float outsideCutoff = maxThickness + _FurTouchRange * 0.01;

				if (outsideCutoff > insideCutoff)
				{
					float2 direction = float2(0, 0);
					float strength = 0;
					float samples = 0;

					// Surfaces that are sloping away are especially sensitive to 'jitter', because the depth won't
					// be even for all samples. We can compensate for some of this by having a maximum depth.
#if defined(USING_STEREO_MATRICES)
					float maxVertexDepth = -0.5 * (mul(unity_StereoMatrixV[0], float4(o.worldPos.xyz, 1)).z + mul(unity_StereoMatrixV[1], float4(o.worldPos.xyz, 1)).z);
#else
					float maxVertexDepth = -mul(unity_MatrixV, float4(o.worldPos.xyz, 1)).z;
#endif
					for (float ring = 1; ring <= 4; ring++)
					{
						float maxAngles = 2.0 + ring * 2.0;
						float sliceSize = 6.283185307 / maxAngles;
						for (float slice = 0; slice < maxAngles; slice++)
						{
							float myAngle = (slice + 0.5) * sliceSize;
							float2 scanPoint = float2(sin(myAngle), cos(myAngle)) * ring * 0.25;
#define FUR_CONTACT_SIZE 1.25
							float4 vertexWorldPos = float4(o.worldPos.xyz + (((worldTangent.xyz * scanPoint.x) + (worldBinormal.xyz * scanPoint.y)) * worldThickness * FUR_CONTACT_SIZE), 1);

							// Stereo rendering. We want the average between both eyes so that the fur moves the same in both.
#if defined(USING_STEREO_MATRICES)
							int currentEye = unity_StereoEyeIndex;

							float vertexCameraSpaceDepth = -0.5 * (mul(unity_StereoMatrixV[0], vertexWorldPos).z + mul(unity_StereoMatrixV[1], vertexWorldPos).z);

							unity_StereoEyeIndex = 0;
							float4 vertexClipSpace0 = mul(unity_MatrixVP, vertexWorldPos);
							float2 vertexScreenSpace0 = ComputeScreenPos(vertexClipSpace0).xy;
							float shadowDepth0 = LinearEyeDepth(SAMPLE_DEPTH_TEXTURE_LOD(_CameraDepthTexture, float4(vertexScreenSpace0 / vertexClipSpace0.w, 0, 0)));

							unity_StereoEyeIndex = 1;
							float4 vertexClipSpace1 = mul(unity_MatrixVP, vertexWorldPos);
							float2 vertexScreenSpace1 = ComputeScreenPos(vertexClipSpace1).xy;
							float shadowDepth1 = LinearEyeDepth(SAMPLE_DEPTH_TEXTURE_LOD(_CameraDepthTexture, float4(vertexScreenSpace1 / vertexClipSpace1.w, 0, 0)));

							unity_StereoEyeIndex = currentEye;
							float shadowDepth = (shadowDepth0 + shadowDepth1) * 0.5;
#else
							// Mono rendering
							float vertexCameraSpaceDepth = -mul(unity_MatrixV, vertexWorldPos).z;

							float4 vertexClipSpace = mul(unity_MatrixVP, vertexWorldPos);
							float2 vertexScreenSpace = ComputeScreenPos(vertexClipSpace).xy;
							float shadowDepth = LinearEyeDepth(SAMPLE_DEPTH_TEXTURE_LOD(_CameraDepthTexture, float4(vertexScreenSpace / vertexClipSpace.w, 0, 0)));
#endif
							// Enforce a maximum depth (and yes, 'min' is correct for this, since we don't want anything larger than the maximum)
							vertexCameraSpaceDepth = min(vertexCameraSpaceDepth, maxVertexDepth);

							float contactDistance = vertexCameraSpaceDepth - shadowDepth;
#if defined(UNITY_SINGLE_PASS_STEREO)
							contactDistance *= 2.0;
#endif

							// The larger the sweet-spot, the less sensitive the touch detection is to the hand needing to be at just the right
							// height for maximum displacement. However, this can cause more false-triggering.
#define FUR_CONTACT_SWEETSPOT 2.0
							float sampleStrength = saturate((0.5 - abs(0.5 - saturate(smoothstep(insideCutoff, outsideCutoff, contactDistance)))) * FUR_CONTACT_SWEETSPOT);

							samples += sampleStrength > 0 ? 1 : 0;
							strength = saturate(strength + sampleStrength);
							direction += scanPoint.xy * (sampleStrength > 0 ? 1 : 0);
						}
						if (length(direction) > 1.0) direction = normalize(direction);

						if (strength > 0.1 && samples > 2)
						{
							// If we have less than 5 samples, then exponentially decrease the strength. This dramatically reduces 'jitter'.
							strength *= saturate(samples * samples * 0.04);
							strength *= strength;
							strength *= saturate((contactActive - 1.0) * 5.0);
							strength *= saturate((1.0 - viewDistance) * 10.0);
							// How strong should the displacement be?
#define FUR_CONTACT_STRENGTH 2.0
							strength *= FUR_CONTACT_STRENGTH;
							direction *= strength * saturate((FUR_CONTACT_CULLTEST - o.FURCULLTEST) * 10.0) * _FurTouchStrength;
							touchVector.xyz += (worldTangent.xyz * direction.x) + (worldBinormal.xyz * direction.y);
							// How much should the fur squish down when being displaced?
#define FUR_CONTACT_COMPRESSION 0.25
							worldThickness *= (1.0 - saturate(strength * FUR_CONTACT_COMPRESSION * _FurTouchStrength));

#if defined (FUR_DEBUGGING)
							if (_FurDebugContact > 0.5) o.lightData1.b += strength;
#endif
						}
					}
				}
			}
		}
	}
	o.windEffect.xyz = windVector + windTurbulence + touchVector;
#endif



#if !defined (PREPASS)
	//--------------------------------------------------------------------------------
	// Calculate Lighting
	//--------------------------------------------------------------------------------

	// Recalulate the normal so that wind, gravity, and movement will affect reflected light.
	float3 lightingNormal = normalize(o.worldNormal.xyz - ((float3(0, _FurGravitySlider * -0.75, 0) + windVector + (windTurbulence * _FurWindShimmer) + (touchVector * 0.3)) * 0.25));


	// Calculate the baked lighting
#if defined(LIGHTMAP_ON)
	float2 lightmapUV = v.uv1 * unity_LightmapST.xy + unity_LightmapST.zw;
	o.lightData1.rgb += DecodeLightmap(UNITY_SAMPLE_TEX2D_LOD(unity_Lightmap, lightmapUV, 0));
#endif


	// If the fur is facing the camera, it won't have sub-surface scattering
	float scatterAtten = 0;
	if (_SubsurfaceScattering > 0) scatterAtten = saturate(dot(viewDir, o.worldNormal.xyz));
	// Calculate the reflection angle, for adding a metallic tint to the fur
	float3 reflection = reflect(-viewDir, lightingNormal);
#if defined(_METALLICGLOSSMAP)
	float2 metallicMap = tex2Dlod(_MetallicGlossMap, float4(uv, 1, 0)).ra;
	float metallic = metallicMap.r * _Metallic;
#else
	float metallic = _Metallic;
#endif
	float oneMinusMetallic = 1 - metallic;


	//--------------------------------------------------------------------------------
	// "Important" world space lights
	bool lightOn = any(_LightColor0.rgb >= 0.002) && _LightColor0.a >= 0.002;
	float3 lightDir = _WorldSpaceLightPos0.xyz;
	if (!lightOn && _FallbackLightEnable > 0)
	{
		float lightYCos = cos(radians(_FallbackLightAngle));
		lightDir = normalize(float3(sin(radians(_FallbackLightDirection)) * lightYCos, -sin(radians(_FallbackLightAngle)), cos(radians(_FallbackLightDirection)) * lightYCos));
		lightOn = true;
	}
	if (lightOn)
	{
#if defined(POINT) || defined(SPOT)
		lightDir = normalize(lightDir - o.worldPos.xyz);
#endif


		// Diffuse (Lambertian)
		o.MAINLIGHTDOT = (dot(o.worldNormal.xyz, lightDir) * oneMinusMetallic) + (dot(reflection, lightDir) * metallic);


		// Anisotropic reflections. This isn't even close to being correct, but doing things correctly means
		// doing it mostly in the fragment shader, which cuts frame rate by about 1/3, so it's not an option.
		if (_FurAnisotropicEnable > 0)
		{
			// Get the direction that the hair is pointing.
			float3 hairVector = (float3(furShape.xy, 0) * 2 - 1) * _FurCombStrength;
			hairVector.z = sqrt(1 - dot(hairVector.xy, hairVector.xy));
			hairVector = normalize(hairVector.x * worldTangent.xyz + hairVector.y * worldBinormal + hairVector.z * normalize(lightingNormal) * (1.001 - _FurAnisoFlat));
			hairVector = normalize(hairVector - (float3(0, _FurGravitySlider * -0.75, 0) + windVector + (windTurbulence * _FurWindShimmer)) * 0.25);

			// If the light hits the hair at right angle, it reflects outwards in a disc.
			// As it hits at steeper angles, that disc turns into a cone. However, the hair
			// also has a prism-like structure, so it will add an offset to the angle of reflection.
			// Combining these two factors gives us a cone-shaped angle. The closer the view
			// direction is to this angle, the brighter the reflection/refraction.

			// Start by getting the dot product of the hair and the light vectors. If the light
			// is hitting at a right angle, the result will be 0. If it is hitting the hair straight
			// on the result will be -1.
			float lightDot = dot(hairVector, lightDir);

			// The light will reflect off at an angle that is biased towards the hair tip due to
			// the structure of the hair. The property sliders control the amount of bias. We are
			// just adding a linear bias, which isn't correct, but it's simple to calculate.
			float2 anisoAngle = lightDot + float2(_FurAnisoReflectAngle, _FurAnisoRefractAngle) * 0.01111;

			// Now get the dot product of the hair and the view angle. If the negative of the product
			// (negative because we are viewing from the opposite direction) is close to of the
			// reflect/refract angles, then the light will be visible.
			float hairAndViewDot = -dot(hairVector, -viewDir);

			// Glossiness determines how wide the possible view angle difference is.
			float2 anisoGloss = float2(_FurAnisoReflectGloss, _FurAnisoRefractGloss);
			float2 anisoSetting = float2(_FurAnisotropicReflect, _FurAnisotropicRefract);
			float2 glossFactor = 0.35 + (anisoGloss * anisoGloss);
			float2 anisoStrength = saturate((1 - abs(anisoAngle - hairAndViewDot)) - (0.65 + anisoGloss * 0.2)) * glossFactor;
			o.ANISOTROPICBOTH = (anisoStrength * anisoSetting);
			o.ANISOTROPICANGLE = (anisoAngle.x - hairAndViewDot) * glossFactor.x;



			// EXPERIMENTAL
			/*float anisotropic1Reflect;
			float anisotropic2Refract;

			// Anisotropic
			float anisoBaseStrength = 1;
			anisotropic1Reflect = anisoBaseStrength * (1 + _FurAnisoReflectMetallic);
			anisotropic2Refract = anisoBaseStrength * (1 + _FurAnisoRefractMetallic);
			float aniosoEnergyConservation = ((anisotropic1Reflect * _FurAnisotropicReflect * (1 + _FurAnisoReflectGloss * 0.5)) + (anisotropic2Refract * _FurAnisotropicRefract * (1 + _FurAnisoRefractGloss * 0.5))) * 0.025;

			anisoBaseStrength *= saturate(o.MAINLIGHTDOT);
			anisotropic1Reflect *= o.ANISOTROPIC1REFLECT * saturate(o.MAINLIGHTDOT);
			anisotropic2Refract *= o.ANISOTROPIC2REFRACT * saturate(o.MAINLIGHTDOT);

			float3 anisoReflectColor = _FurAnisotropicReflectColor * _LightColor0.rgb;

			if (_FurAnisoReflectIridescenceStrength > 0 && anisotropic1Reflect > 0) anisoReflectColor = (anisoReflectColor * (1 - (_FurAnisoReflectIridescenceStrength * 0.05))) +
				(_FurAnisoReflectIridescenceStrength * 0.05 * (
				((_FurAnisotropicReflectColor * saturate(1 - abs(o.ANISOTROPICANGLE * _FurAnisoReflectIridescenceStrength))) +
				((_FurAnisotropicReflectColorNeg * saturate(-o.ANISOTROPICANGLE * _FurAnisoReflectIridescenceStrength)) +
				((_FurAnisotropicReflectColorPos * saturate(o.ANISOTROPICANGLE * _FurAnisoReflectIridescenceStrength)))))));
			float3 aniso1ReflectColour = (_LightColor0.rgb + (anisotropic1Reflect > 0 ? _FurAnisoReflectEmission : 0)) * anisotropic1Reflect * anisoReflectColor;

			float3 aniso2RefractColour = (_LightColor0.rgb + (anisotropic2Refract > 0 ? _FurAnisoRefractEmission : 0)) * anisotropic2Refract * _FurAnisotropicRefractColor;

			o.specularLight.rgb = (aniso1ReflectColour + aniso2RefractColour) *  _TS2;*/

		}


		// Simulate subsurface scattering. This isn't accurate at all, but accurate != fast.
		// The basic idea is that if the viewer is behind the avatar, facing towards the light,
		// light will be visible from fur that is perpendicular to the viewer.
		if (_SubsurfaceScattering > 0)
		{
			float scatterStrength = dot(viewDir, -lightDir);// Is the camera looking past our position and into the light?
			scatterStrength -= scatterAtten * 1.25;// Is the fur facing the camera? If so, the light gets blocked.

			o.SUBSURFACESTRENGTH = saturate(scatterStrength) * _SubsurfaceScattering;
			//o.lightData1.rgb += min(_LightColor0, _MaxBrightness) * saturate(scatterStrength) * _SubsurfaceScattering;
		}
	}


	// Optionally re-mix some of the 'important' light into ambient
	// This doesn't handle SPOT or POINT lights because those require a texture
	// sample to calculate the attentuation, which isn't worth the FPS cost.
#if defined(DIRECTIONAL)
	o.lightData1.rgb += min(_LightColor0, _MaxBrightness) * (_SoftenShadows * 0.1);
#endif


#if defined(FORWARD_BASE_PASS)
	//--------------------------------------------------------------------------------
	// Vertex lighting
	float oneMinusSoftenShadows = 1.0 - (_SoftenShadows * 0.1);

	// Apply the 4 vertex lights (which are always point lights). This code is copy-pasted from UnityCG.cginc, but has been
	// modified to add extra features.
#if defined(VERTEXLIGHT_ON)
	// to light vectors
	float4 toLightX = unity_4LightPosX0 - o.worldPos.x;
	float4 toLightY = unity_4LightPosY0 - o.worldPos.y;
	float4 toLightZ = unity_4LightPosZ0 - o.worldPos.z;
	// squared lengths
	float4 lengthSq = 0;
	lengthSq += toLightX * toLightX;
	lengthSq += toLightY * toLightY;
	lengthSq += toLightZ * toLightZ;
	// don't produce NaNs if some vertex position overlaps with the light
	lengthSq = max(lengthSq, 0.000001);

	// NdotL
	float4 ndotl = 0;
	ndotl += toLightX * o.worldNormal.x * oneMinusMetallic;
	ndotl += toLightY * o.worldNormal.y * oneMinusMetallic;
	ndotl += toLightZ * o.worldNormal.z * oneMinusMetallic;
	ndotl += toLightX * reflection.x * metallic;
	ndotl += toLightY * reflection.y * metallic;
	ndotl += toLightZ * reflection.z * metallic;
	// correct NdotL
	float4 corr = rsqrt(lengthSq);
	ndotl = max(float4(0, 0, 0, 0), ndotl * corr);
	ndotl *= oneMinusMetallic + (2 * metallic * pow(ndotl, 1 + metallic * 15));
	// attenuation
	float4 atten = 1.0 / (1.0 + lengthSq * unity_4LightAtten0);
	float4 diff = (ndotl * atten * oneMinusSoftenShadows) + (atten * (_SoftenShadows * 0.1));
	// final color
	o.lightData1.rgb += unity_LightColor[0].rgb * diff.x;
	o.lightData1.rgb += unity_LightColor[1].rgb * diff.y;
	o.lightData1.rgb += unity_LightColor[2].rgb * diff.z;
	o.lightData1.rgb += unity_LightColor[3].rgb * diff.w;

	if (_SubsurfaceScattering > 0)
	{
		float4 cameraToLightX = _WorldSpaceCameraPos.x - unity_4LightPosX0;
		float4 cameraToLightY = _WorldSpaceCameraPos.y - unity_4LightPosY0;
		float4 cameraToLightZ = _WorldSpaceCameraPos.z - unity_4LightPosZ0;
		float4 scatterStrength = 0;
		scatterStrength += cameraToLightX * viewDir.x;
		scatterStrength += cameraToLightY * viewDir.y;
		scatterStrength += cameraToLightZ * viewDir.z;
		scatterStrength -= scatterAtten * 3;// Is the fur facing the camera? If so, the light gets blocked.

		diff = max(0, (scatterStrength * atten * oneMinusSoftenShadows) + (atten * (_SoftenShadows * 0.1))) * 0.4;
		o.lightData1.rgb += unity_LightColor[0].rgb * diff.x;
		o.lightData1.rgb += unity_LightColor[1].rgb * diff.y;
		o.lightData1.rgb += unity_LightColor[2].rgb * diff.z;
		o.lightData1.rgb += unity_LightColor[3].rgb * diff.w;
	}
#endif



	// Spherical harmonics lights
	o.lightData1.rgb += ShadeSH9(float4(o.worldNormal.xyz, 1)) * oneMinusMetallic;
	o.lightData1.rgb += ShadeSH9(float4(reflection, 1)) * metallic * 0.25;
	o.lightData1.rgb += (_SoftenShadows * 0.4) * ShadeSH9(float4(-o.worldNormal.xyz, 1));
	o.lightData1.rgb = min(o.lightData1.rgb, _MaxBrightness);

	if (_SubsurfaceScattering > 0)
	{
		float diff = max(0, ((1 - (scatterAtten * 3)) * oneMinusSoftenShadows) + (_SoftenShadows * 0.1)) * 0.4;
		o.lightData1.rgb += ShadeSH9(float4(-viewDir, 1)).rgb * diff * _SubsurfaceScattering;
	}


	if (_WorldLightReColourStrength > 0)
	{
		float brightness = (o.lightData1.r * 0.30 + o.lightData1.g * 0.59 + o.lightData1.b * 0.11);
		o.lightData1.rgb = (o.lightData1.rgb * (1 - _WorldLightReColourStrength)) + (_WorldLightReColour.rgb * _WorldLightReColourStrength * brightness);
	}

	// Extra Rim/Front lighting
	if (_ExtraLightingEnable > 0)
	{
		float strength = _ExtraLighting;
		if (_ExtraLightingRim != 0)
		{
			float dotView = dot(o.worldNormal.xyz, viewDir);

			if (_ExtraLightingRim > 0)
			{
				strength *= pow(abs(dot(o.worldNormal.xyz, viewDir)), _ExtraLightingRim);
			}
			else
			{
				strength *= pow(1 - abs(dot(o.worldNormal.xyz, viewDir)), 0 - _ExtraLightingRim);
			}
		}
		if (_ExtraLightingMode > 0)
		{
			o.lightData1.rgb = max(o.lightData1.rgb, _ExtraLightingColor * strength);
		}
		else
		{
			o.lightData1.rgb += _ExtraLightingColor * strength;
		}
	}
#endif

	//o.lightData1.rgb = moveLight;

#if defined(FUR_USE_SHADOWS) && (defined(SHADOWS_SCREEN) || defined(SHADOWS_DEPTH) || defined(SHADOWS_CUBE))
	//--------------------------------------------------------------------------------
	// Process shadows
   // At extremly close ranges we need to shrink the shadows, otherwise the camera will be inside the shadow casting radius, which will cause glitches
	shadowStruct tempOut;
#if defined(FUR_SKIN_ONLY)
	tempOut.pos = UnityObjectToClipPos(v.vertex);
#else
	float shadowHeight = 0;
	if (_FurTouchStrength == 0) shadowHeight = 0.95 * thicknessSample * _ScaleCalibration * _OverrideScale * _FurShellSpacing * _FurShadowCastSize * saturate((viewDistance - 0.035) * 20);

	tempOut.pos = UnityObjectToClipPos(v.vertex + v.normal.xyz * shadowHeight);
#endif
	TRANSFER_SHADOW(tempOut);
	o._ShadowCoord = tempOut._ShadowCoord;
#endif
#endif



#if defined(FUR_SKIN_LAYER)
	//--------------------------------------------------------------------------------
	// Process skin layer (then exit)
   // Note that the skin layer packs the ZDATA differently than the fur layers.
   // It just packs the skin position without any fancy modulus stuf...
	o.ZDATA = skinZ;

	float bend = pow(_HairStiffness * 0.85 + ((1 - _HairStiffness) * skinZ), 2);
	float3 adjustedScaledNormal = normalize(o.worldNormal.xyz - ((saturate(o.FURFADEIN * 5.0) * windVector) + float3(0, _FurGravitySlider, 0)) * bend) * worldThickness;

	o.worldPos.xyz += adjustedScaledNormal * skinZ;
	o.pos = UnityWorldToClipPos(o.worldPos.xyz);
	UNITY_TRANSFER_FOG(o, o.pos);
	return o;
#else



	//--------------------------------------------------------------------------------
	// Process fur layers
	o.WORLDTHICKNESS = worldThickness;
	o.SKIN_Z = skinZ;



	//--------------------------------------------------------------------------------
	// Where is this vertex on the visible screen? 0 = centre, >1 = off-screen
	float3 firstOffset = o.worldNormal.xyz * worldThickness * thicknessSample;
	float3 secondOffset = normalize(o.worldNormal.xyz - (o.windEffect.xyz + float3(0, _FurGravitySlider, 0))) * worldThickness * thicknessSample;
	// Create a triangle where one corner is the root position, the second is where the hair tip would be if there
	// was no wind/gravity, and the third is the actual hair tip location. The Hull shader will use this to determine
	// if the resulting triangle-of-triangles is visible or not.
	float4 pos0 = UnityWorldToClipPos(o.worldPos.xyz);
	float4 pos1 = UnityWorldToClipPos(o.worldPos.xyz + firstOffset);
	float4 pos2 = UnityWorldToClipPos(o.worldPos.xyz + secondOffset);
	float3 screenPos0 = pos0.xyz / pos0.w;
	float3 screenPos1 = pos1.xyz / pos1.w;
	float3 screenPos2 = pos2.xyz / pos2.w;
	o.screenPosMin = min(HULL_SCREEN_CULLING, max(-HULL_SCREEN_CULLING, min(min(screenPos0.xy, screenPos1.xy), screenPos2.xy)));
	o.screenPosMax = min(HULL_SCREEN_CULLING, max(-HULL_SCREEN_CULLING, max(max(screenPos0.xy, screenPos1.xy), screenPos2.xy)));



	// If we are out of range then mark that we don't want any layers and exit
	if (shellsToRender < 0.33)
	{
		o.VISIBLELAYERS = 0;
		return o;
	}



	//--------------------------------------------------------------------------------
	// Determine how many shells to render, based on density.
#if defined(PIPELINE3)
#if defined(LITEFUR)
	float maxShells = 16 + max(0, quality - 1) * 8;
#else
	float maxShells = 32 + max(0, quality - 1) * 16;
#endif
#else
	float maxShells = GEOM_MAX_SHELL;
#endif

	// Apply the middle-limit. This is to prevent extreme, face-in-floof close-ups from turning into slide-shows.
	shellsToRender = min(shellsToRender, MID_SHELLS_FACTOR * maxShells);

	// Gradually enhance all fur towards edges (reduces dot-crawl when zooming in/out and reduces visible gaps in the edges of the fur)
	shellsToRender *= 4.0 - (4.0 * (saturate(abs(o.FURCULLTEST) + 0.25) - 0.25));

	// Apply the max limit
	shellsToRender = min(shellsToRender, maxShells - MIN_SHELLS);

	// If the fur has been compressed because it's below half-height, remove some layers so that the resulting
	// density is half-way between the "normal" density and the compressed density.
	if (shellsToRender > 2) shellsToRender = lerp(2, shellsToRender, saturate(0.5 + thicknessSample));

#if defined (USING_STEREO_MATRICES)
	// If we are in VR, then we can gradually lower the resolution near the edges, thanks to the fact that
	// current VR lenses kinda suck and everything gets blurry away from the centre.
	shellsToRender *= max(0.5, saturate(1.35 - length(screenPos0)));
#endif

	o.VISIBLELAYERS = MIN_SHELLS + shellsToRender;
	o.MAX_Z = thicknessSample;

	return o;
#endif
}
